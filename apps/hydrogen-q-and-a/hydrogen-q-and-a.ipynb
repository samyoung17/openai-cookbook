{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import openai\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers import GPT2TokenizerFast\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "openai.api_key_path = '/Users/samyoung/.openai-api-key.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Notion allows exporting a page (and all subpages), as a folder containing manifest .md files.\n",
    "wiki_paths = list(Path('fine_tuning_wikis/hydrogen_domain').rglob('*.md'))\n",
    "wikis = [open(wiki_path).read() for wiki_path in wiki_paths]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"count the number of tokens in a string\"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "def reduce_long(\n",
    "    long_text: str, long_text_tokens: bool = False, max_len: int = 590\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Reduce a long text to a maximum of `max_len` tokens by potentially cutting at a sentence end\n",
    "    \"\"\"\n",
    "    if not long_text_tokens:\n",
    "        long_text_tokens = count_tokens(long_text)\n",
    "    if long_text_tokens > max_len:\n",
    "        sentences = long_text.split('\\n')\n",
    "        ntokens = 0\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            ntokens += 1 + count_tokens(sentence)\n",
    "            if ntokens > max_len:\n",
    "                return \"\\n\".join(sentences[:i])\n",
    "\n",
    "    return long_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "\n",
    "def split_sections(wiki_text):\n",
    "    headings = re.findall(\"#.*\\n\", wiki_text)\n",
    "    for heading in headings:\n",
    "        wiki_text = wiki_text.replace(heading, \"==+ !! ==+\")\n",
    "    contents = wiki_text.split(\"==+ !! ==+\")\n",
    "    contents = [c.strip() for c in contents]\n",
    "    assert len(headings) == len(contents) - 1\n",
    "    return headings, contents\n",
    "\n",
    "def build_dataframe(headings, contents, page_name, max_tokens=1500):\n",
    "    df = pd.DataFrame({'heading': headings, 'content': contents[1:], 'page_name': page_name, 'title': headings[0]})\n",
    "    df = df[df.content != '']\n",
    "    df['context'] = df['heading'] + df['content']\n",
    "    df['n_tokens_before'] = df['context'].apply(count_tokens)\n",
    "    df['context'] = np.where(df['n_tokens_before'] > max_tokens,\n",
    "                             df.context.apply(lambda ctx: reduce_long(ctx, max_len=max_tokens)),\n",
    "                             df.context)\n",
    "    df['tokens'] = df['context'].apply(count_tokens)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for wiki, path in zip(wikis, wiki_paths):\n",
    "    headings, contents = split_sections(wiki)\n",
    "    x = build_dataframe(headings, contents, path.name)\n",
    "    dfs.append(x)\n",
    "df = pd.concat(dfs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 56 entries, 1 to 6\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   heading          56 non-null     object\n",
      " 1   content          56 non-null     object\n",
      " 2   page_name        56 non-null     object\n",
      " 3   title            56 non-null     object\n",
      " 4   context          56 non-null     object\n",
      " 5   n_tokens_before  56 non-null     int64 \n",
      " 6   tokens           56 non-null     int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def get_questions(context):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci-instruct-beta-v3\",\n",
    "            prompt=f\"Write questions based on the text below\\n\\nText: {context}\\n\\nQuestions:\\n1.\",\n",
    "            temperature=0,\n",
    "            max_tokens=257,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=[\"\\n\\n\"]\n",
    "        )\n",
    "        return response['choices'][0]['text']\n",
    "    except:\n",
    "        return \"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:48<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is an asset in the context of hydrogen generation?\n",
      "2. What is a delivery site?\n",
      "3. What is a generation unit?\n",
      "4. What is an order?\n",
      "5. What is a schedule?\n",
      "6. What is a tariff?\n",
      "7. What is a balance of plant?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df['questions'] = '1.' + df.context.progress_apply(get_questions)\n",
    "print(df[['questions']].values[0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [01:08<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. An asset in the context of hydrogen generation is an item that is involved in the generation and delivery of hydrogen.\n",
      "2. A delivery site is a location that we deliver hydrogen to. A customer who purchases hydrogen may have one or more delivery sites.\n",
      "3. A generation unit is a co-located grouping of assets that generate hydrogen (electrolysers and compressors). Our first site will have one electrolyser connected to one compressor, but in future, we may run multiple electrolysers, and/or multiple compressors, in parallel within a generation unit.\n",
      "4. An order is a request for a volume of hydrogen to be made available for use at a specified time and location. Orders must also include the pressure that is required by the vehicle being filled as this will impact the dispensable volume of a storage unit.\n",
      "5. A schedule is a list of instructions for a window of time that must be followed in order to fulfil one or more hydrogen orders within the window in an optimal way.\n",
      "6. A tariff is the price we pay for energy at a particular site. Comes in many types and levels of granularity from a single price per kWh to half-hourly varying prices depending on demand and other factors.\n",
      "7. Balance of plant (\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_answers(row):\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci-instruct-beta-v3\",\n",
    "            prompt=f\"Write answer based on the text below\\n\\nText: {row.context}\\n\\nQuestions:\\n{row.questions}\\n\\nAnswers:\\n1.\",\n",
    "            temperature=0,\n",
    "            max_tokens=257,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        return response['choices'][0]['text']\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "df['answers']= df.progress_apply(get_answers, axis=1)\n",
    "df['answers'] = \"1.\" + df.answers\n",
    "df = df.dropna().reset_index().drop('index',axis=1)\n",
    "print(df[['answers']].values[0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "Path('results').mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv('results/hydrogen_q_and_a.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   heading          56 non-null     object\n",
      " 1   content          56 non-null     object\n",
      " 2   page_name        56 non-null     object\n",
      " 3   title            56 non-null     object\n",
      " 4   context          56 non-null     object\n",
      " 5   n_tokens_before  56 non-null     int64 \n",
      " 6   tokens           56 non-null     int64 \n",
      " 7   questions        56 non-null     object\n",
      " 8   answers          56 non-null     object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "qa = df.apply(lambda row: list(zip(row['questions'].split('\\n'), row['answers'].split('\\n'))), axis=1).tolist()\n",
    "qa_flat = [item for sublist in qa for item in sublist]\n",
    "qadf = pd.DataFrame(qa_flat)\n",
    "qadf.columns=['question', 'answer']\n",
    "qadf.to_csv('results/qadf.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
